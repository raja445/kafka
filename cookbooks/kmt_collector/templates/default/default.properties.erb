app.name=kmt
mirroring.namespace=Collector
spooling.path=/data/inmobi/kafkamirroring/spooling

#HDFSProducer Flags
hdfs.principal.name=kmt
hdfs.expiry.mins=5

#hdfs.error.location=kafka/error
#hdfs.temp.location=kafka/working
#hdfs.expiry.location=kafka/expiry

#Limits
hdfs.folder.limit=1000
hdfs.batch.flush=10000
hdfs.file.limit=128000000

#In case of lot files piled and wants to clean them, using thread pool.
local.shifterpool.size=5
#If more than 3 mins files found, they will be marked as invalid or old depending up the state of the file.
local.staging.threshold=1
local.staging.dealy=5
local.staging.path=/data/kafka/staging/

#timer tasks
populate.streams=30
cleanup.deadnodes=30
try.streams=120
clean.streams=60
reaload.config=120

#zk/file/hdfs
zk.basesleeptime=1000
zk.maxretries=3
offset.read=zk
offset.file.location=/data/inmobi/kafkamirroring/offsets

channelpool.size=10
enable.zero.bytes.file=false
auto.commit.interval=10000
reload.newpartitions=300


prod.colos=<%= @collector_id %>
<%= @collector_id %>.config={"configs":[{"name":"<%= @colo %>","url":"hdfs://<%= @hdfs_id %>:8020","regex":"hdfs://[a-z]*:[0-9]*"}]}
